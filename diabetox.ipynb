{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8261ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.7)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "###     DOWNLOAD DATA FROM THE API AND COMPILE IT IN JSON FORMAT        ###\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "BASE_URL = \"https://api.hackupm2025.workers.dev/api/v1/patients\"\n",
    "LIMIT = 100\n",
    "\n",
    "def fetch_all_patients(endpoint: str):\n",
    "    \"\"\"Fetch all patients from a given API endpoint ('test' or 'train').\"\"\"\n",
    "    page = 1\n",
    "    all_patients = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"page\": page, \"limit\": LIMIT}\n",
    "        url = f\"{BASE_URL}/{endpoint}\"\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        patients = data.get(\"data\", [])\n",
    "        all_patients.extend(patients)\n",
    "\n",
    "        pagination = data.get(\"pagination\", {})\n",
    "        has_next = pagination.get(\"hasNextPage\", False)\n",
    "\n",
    "        print(f\"[{endpoint.upper()}] Fetched page {page} ‚Üí {len(patients)} records\")\n",
    "\n",
    "        if not has_next:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    print(f\"\\n‚úÖ Done fetching {endpoint} data! Total patients: {len(all_patients)}\\n\")\n",
    "    return all_patients\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Loop through both endpoints\n",
    "    for endpoint in [\"test\", \"train\"]:\n",
    "        all_data = fetch_all_patients(endpoint)\n",
    "        filename = f\"patients_data_{endpoint}.json\"\n",
    "\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"üíæ Saved {len(all_data)} records to {filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae812d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT FEATURES USING A DOCKERIZED LLM EXPOSING AN OpenAI-compatible API\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# --------------------------\n",
    "# üß† Local LLM Docker server setup\n",
    "# --------------------------\n",
    "# üëá CHANGE THIS LINE: use your Docker container‚Äôs endpoint\n",
    "LLM_API_URL = \"http://localhost:8000/v1/chat/completions\"\n",
    "MODEL_NAME = \"local-llm\"  # placeholder, can be anything\n",
    "\n",
    "# --------------------------\n",
    "# ü©∫ Extraction instructions\n",
    "# --------------------------\n",
    "instructions = \"\"\"You are a clinical data extractor.\n",
    "Given a patient description, return ONLY a JSON with these fields:\n",
    "\n",
    "{\n",
    " \"Age\": integer,\n",
    " \"Gender\": \"Male\" or \"Female\",\n",
    " \"Hypertension\": 0 or 1,\n",
    " \"Heart Disease\": 0 or 1,\n",
    " \"Smoking History\": \"never\" | \"past\" | \"current\" | \"not known\",\n",
    " \"BMI\": float,\n",
    " \"HbA1c\": \"Low\" | \"Normal\" | \"High\" | \"Very High\",\n",
    " \"Random Glucose\": \"Low\" | \"Normal\" | \"High\" | \"Very High\"\n",
    "}\n",
    "\n",
    "Do not add explanations or text outside the JSON.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------\n",
    "# üìÇ Load dataset\n",
    "# --------------------------\n",
    "with open(\"patients_data_test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    patients = json.load(f)\n",
    "\n",
    "# --------------------------\n",
    "# üíæ Output setup\n",
    "# --------------------------\n",
    "OUTPUT_FILE = \"extracted_patients_data.csv\"\n",
    "\n",
    "# Resume if partial CSV exists\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    existing_df = pd.read_csv(OUTPUT_FILE)\n",
    "    processed_indices = set(existing_df[\"index\"].tolist())\n",
    "    results = existing_df.to_dict(orient=\"records\")\n",
    "    print(f\"üìÑ Resuming from previous run ({len(processed_indices)} patients already processed)\")\n",
    "else:\n",
    "    processed_indices = set()\n",
    "    results = []\n",
    "\n",
    "# --------------------------\n",
    "# üîÅ Iterate through each patient\n",
    "# --------------------------\n",
    "for i, patient in enumerate(patients, start=1):\n",
    "    if i in processed_indices:\n",
    "        print(f\"‚è© Skipping patient {i} (already processed)\")\n",
    "        continue\n",
    "\n",
    "    medtext = patient[\"medical_note\"]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": medtext}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,  # üëà using your local Docker endpoint now\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": 0.1,\n",
    "                \"max_tokens\": 512\n",
    "            },\n",
    "            timeout=120  # give the local model some time\n",
    "        )\n",
    "\n",
    "        response.raise_for_status()\n",
    "        output = response.json()\n",
    "        content = output[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"‚ö†Ô∏è Could not parse JSON for patient {i}\")\n",
    "            data = {}\n",
    "\n",
    "        data[\"index\"] = i\n",
    "\n",
    "        # Save incrementally\n",
    "        print(f\"‚úÖ Extracted data for patient {i}: {data}\")\n",
    "        results.append(data)\n",
    "        pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"üíæ Saved progress up to patient {i}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error on patient {i}: {e}\")\n",
    "        error_data = {\"index\": i, \"error\": str(e)}\n",
    "        results.append(error_data)\n",
    "        pd.DataFrame(results).to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# --------------------------\n",
    "# ‚úÖ Done\n",
    "# --------------------------\n",
    "print(\"üèÅ Extraction complete! Data saved to\", OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "###     DATA CLEANUP AND PREPARATION FOR MODELING        ###\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"extracted_patients_data.csv\")\n",
    "\n",
    "# Columns to remove\n",
    "columns_to_remove = [\"Glucose Level\", \"Low\", \"Low Risk\", \"Blood Pressure\", \"Glucose Levels\"]\n",
    "\n",
    "# Remove columns if they exist\n",
    "df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# Drop rows with any null (missing) values\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the cleaned CSV\n",
    "df.to_csv(\"cleaned_patients_data.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Columns removed, null rows deleted, and cleaned file saved as 'cleaned_patients_data.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
