llama-cpp-python==0.3.5
fastapi==0.115.0
uvicorn==0.30.0
